#######################################################################################
#EFA_CFA_template.R is licensed under a Creative Commons Attribution - Non commercial 3.0 Unported License. see full license at the end of this file.
#######################################################################################
#this script follows a combination of the guidelines proposed by Hadley Wickham http://goo.gl/c04kq as well as using the formatR package http://goo.gl/ri6ky
#if this is the first time you are conducting an analysis using this protocol, please watch http://goo.gl/DajIN while following step by step
#link to manuscript
#####################################################################################
#SETTING ENVIRONMENT
#####################################################################################
#remove all objects and then check
rm(list = ls())
ls()
#dettach all packages
detach()
#command below will install individual and is only run once. remove the hash tag if this is the first time you are running the code on RStudio, and then you can add the hash tag again
install.packages("car", repos="http://cran.r-project.org")
install.packages("ggplot2", repos="http://cran.r-project.org")
install.packages("psych", repos="http://cran.r-project.org")
install.packages("nortest", repos="http://cran.r-project.org")
install.packages("moments", repos="http://cran.r-project.org")
#######################################################################################
#EFA_CFA_template.R is licensed under a Creative Commons Attribution - Non commercial 3.0 Unported License. see full license at the end of this file.
#######################################################################################
#this script follows a combination of the guidelines proposed by Hadley Wickham http://goo.gl/c04kq as well as using the formatR package http://goo.gl/ri6ky
#if this is the first time you are conducting an analysis using this protocol, please watch http://goo.gl/DajIN while following step by step
#link to manuscript
#####################################################################################
#SETTING ENVIRONMENT
#####################################################################################
#remove all objects and then check
rm(list = ls())
ls()
#dettach all packages
detach()
#command below will install individual and is only run once. remove the hash tag if this is the first time you are running the code on RStudio, and then you can add the hash tag again
# install.packages("car", repos="http://cran.r-project.org")
# install.packages("ggplot2", repos="http://cran.r-project.org")
# install.packages("psych", repos="http://cran.r-project.org")
# install.packages("nortest", repos="http://cran.r-project.org")
# install.packages("moments", repos="http://cran.r-project.org")
#command below will install each package. if you run this script from the beginning you need to run every single one again
library("ggplot2")
library("car")
library("psych")
library("irr")
library("nortest")
library("moments")
#uploading data ------------------------------------------------------------------------
#Functions to pull the dara from the internet file
options(RCurlOptions = list(capath = system.file("CurlSSL", "cacert.pem", package = "RCurl"), ssl.verifypeer = FALSE))
#see http://goo.gl/mQwxO on how to get this link
data1 <- getURL("https://docs.google.com/spreadsheet/pub?key=0AoTReYGK49h_dEFHWXVfODR0NlZWdXFoVTZjT09oc0E&single=true&gid=1&output=csv
")
data<-read.csv(textConnection(data1))
#data for ICC analysis
data2 <- getURL("https://docs.google.com/spreadsheet/pub?hl=en&hl=en&key=0AoTReYGK49h_dEFHWXVfODR0NlZWdXFoVTZjT09oc0E&single=true&gid=3&output=csv")
dataicc<-read.csv(textConnection(data2))
#data for correlation analysis
data4 <- getURL("https://docs.google.com/spreadsheet/pub?hl=en&hl=en&key=0AoTReYGK49h_dEFHWXVfODR0NlZWdXFoVTZjT09oc0E&single=true&gid=4&output=csv")
datacor<-read.csv(textConnection(data4))
lapply(c("ggplot2", "psych", "RCurl", "irr", "nortest", "moments"), library, character.only=T)
options(RCurlOptions = list(capath = system.file("CurlSSL", "cacert.pem", package = "RCurl"), ssl.verifypeer = FALSE))
data1 <- getURL("https://docs.google.com/spreadsheet/pub?key=0AoTReYGK49h_dEFHWXVfODR0NlZWdXFoVTZjT09oc0E&single=true&gid=1&output=csv
")
data<-read.csv(textConnection(data1))
data2 <- getURL("https://docs.google.com/spreadsheet/pub?hl=en&hl=en&key=0AoTReYGK49h_dEFHWXVfODR0NlZWdXFoVTZjT09oc0E&single=true&gid=3&output=csv")
dataicc<-read.csv(textConnection(data2))
data4 <- getURL("https://docs.google.com/spreadsheet/pub?hl=en&hl=en&key=0AoTReYGK49h_dEFHWXVfODR0NlZWdXFoVTZjT09oc0E&single=true&gid=4&output=csv")
datacor<-read.csv(textConnection(data4))
dim(data)
summary(data)
library(nFactors)
par(mfrow=c(2,2)) #Command to configure the plot area for the scree plot graph
ev <- eigen(cor(data)) # get eigenvalues - insert the data you want to calculate the scree plot for
ev # Show eigend values
ap <- parallel(subject=nrow(data),var=ncol(data),rep=100,cent=.05) #Calculate the acceleration factor
nS <- nScree(ev$values) #Set up the Scree Plot
plotnScree(nS) # Plot the Graph
kmo = function(# insert data )
{
library(MASS)
X <- cor(as.matrix(data1))
iX <- ginv(X)
S2 <- diag(diag((iX^-1)))
AIS <- S2%*%iX%*%S2
IS <- X+AIS-2*S2
Dai <- sqrt(diag(diag(AIS)))
IR <- ginv(Dai)%*%IS%*%ginv(Dai)
AIR <- ginv(Dai)%*%AIS%*%ginv(Dai)
a <- apply((AIR - diag(diag(AIR)))^2, 2, sum)
AA <- sum(a)
b <- apply((X - diag(nrow(X)))^2, 2, sum)
BB <- sum(b)
MSA <- b/(b+a)
AIR <- AIR-diag(nrow(AIR))+diag(MSA)
kmo <- BB/(AA+BB)
if (kmo >= 0.00 && kmo < 0.50){
test <- 'The KMO test yields a degree of common variance
unacceptable for FA.'
} else if (kmo >= 0.50 && kmo < 0.60){
test <- 'The KMO test yields a degree of common variance miserable.'
} else if (kmo >= 0.60 && kmo < 0.70){
test <- 'The KMO test yields a degree of common variance mediocre.'
} else if (kmo >= 0.70 && kmo < 0.80){
test <- 'The KMO test yields a degree of common variance middling.'
} else if (kmo >= 0.80 && kmo < 0.90){
test <- 'The KMO test yields a degree of common variance meritorious.'
} else {
test <- 'The KMO test yields a degree of common variance marvelous.'
}
ans <- list(  overall = kmo,
report = test,
individual = MSA,
AIS = AIS,
AIR = AIR )
return(ans)
}    # end of the function kmo()
kmo = function()
{
library(MASS)
X <- cor(as.matrix(data1))
iX <- ginv(X)
S2 <- diag(diag((iX^-1)))
AIS <- S2%*%iX%*%S2
IS <- X+AIS-2*S2
Dai <- sqrt(diag(diag(AIS)))
IR <- ginv(Dai)%*%IS%*%ginv(Dai)
AIR <- ginv(Dai)%*%AIS%*%ginv(Dai)
a <- apply((AIR - diag(diag(AIR)))^2, 2, sum)
AA <- sum(a)
b <- apply((X - diag(nrow(X)))^2, 2, sum)
BB <- sum(b)
MSA <- b/(b+a)
AIR <- AIR-diag(nrow(AIR))+diag(MSA)
kmo <- BB/(AA+BB)
if (kmo >= 0.00 && kmo < 0.50){
test <- 'The KMO test yields a degree of common variance
unacceptable for FA.'
} else if (kmo >= 0.50 && kmo < 0.60){
test <- 'The KMO test yields a degree of common variance miserable.'
} else if (kmo >= 0.60 && kmo < 0.70){
test <- 'The KMO test yields a degree of common variance mediocre.'
} else if (kmo >= 0.70 && kmo < 0.80){
test <- 'The KMO test yields a degree of common variance middling.'
} else if (kmo >= 0.80 && kmo < 0.90){
test <- 'The KMO test yields a degree of common variance meritorious.'
} else {
test <- 'The KMO test yields a degree of common variance marvelous.'
}
ans <- list(  overall = kmo,
report = test,
individual = MSA,
AIS = AIS,
AIR = AIR )
return(ans)
}    # end of the function kmo()
kmo(data) #Run the Kmo function for the data you want to calculate
library(psych)
library(GPArotation)
fa(data1,3,fm="pa",rotate="promax") #Functino to exctract the factor loadings. Arguments are DATA, Number of factors, rotation method. Look here http://goo.gl/kY3ln for different methods of estimations or rotations
fa(data,3,fm="pa",rotate="promax") #Functino to exctract the factor loadings. Arguments are DATA, Number of factors, rotation method. Look here http://goo.gl/kY3ln for different methods of estimations or rotations
library (sem)
mod.1 <- specifyModel()
cov <- cov(data, y = NULL, use = "everything", method = c("pearson", "kendall", "spearman"))
sem.1 <- sem(mod.1, cov, N=100) #mod.1 is the model you ahve crated before, cov is the covriance matrix and N argument is the number of observation
mod.1 <- specifyModel()
mod.1 <- specifyModel()
sem.1 <- sem(mod.1, cov, N=100) #mod.1 is the model you ahve crated before, cov is the covriance matrix and N argument is the number of observation
summary(sem.1) # Show summary resutls for SEM
fscore(sem.1) #Show the factor scores for each path in the model
modIndices(sem.1) #Show modification indexes to enhance goodness of fit (suggested to change the model for modification indexes higher than 40, but it is your call)
standardizedCoefficients(sem.1) #Get the standardize coefficientes for each path
standardizedResiduals(sem.1) #Get the residuals for the regressions models
alpha(data, keys=NULL,title=NULL,na.rm = TRUE)
install.packages("ltm")
attach(dataicc)
summary(dataicc)
PAICC<-data.frame(PA,PA2)
ADLICC<-data.frame(ADL,ADL2)
CRICC<-data.frame(CR,CR2)
VGICC<-data.frame(PA,PA2)
install.packages("irr")
library(irr)
icc(PAICC, model="twoway", type="agreement")
icc(ADLICC, model="twoway", type="agreement")
